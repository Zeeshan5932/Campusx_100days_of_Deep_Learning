{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **Types of RNN (with Real-Time Examples & Diagrams)**\n",
        "\n",
        "RNNs are classified based on **how many inputs** and **how many outputs** they handle over time.\n",
        "\n",
        "---\n",
        "\n",
        "## 1ï¸âƒ£ One-to-One RNN\n",
        "\n",
        "*(Not really RNN behavior â€“ acts like ANN)*\n",
        "\n",
        "### Diagram\n",
        "\n",
        "```\n",
        "Input â”€â”€â”€â–º Output\n",
        "```\n",
        "\n",
        "### Example (Real Life)\n",
        "\n",
        "* Image â†’ Label\n",
        "* House features â†’ Price\n",
        "\n",
        "### Explanation\n",
        "\n",
        "* Single input\n",
        "* Single output\n",
        "* No sequence involved\n",
        "\n",
        "ğŸ“Œ **This is basically ANN**, included only for comparison.\n",
        "\n",
        "---\n",
        "\n",
        "## 2ï¸âƒ£ One-to-Many RNN\n",
        "\n",
        "### Diagram\n",
        "\n",
        "```\n",
        "        Output1 â†’ Output2 â†’ Output3\n",
        "           â†‘        â†‘        â†‘\n",
        "Input â”€â”€â”€â”€â”€â”˜â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "### Real-Time Example\n",
        "\n",
        "ğŸ“¸ **Image Captioning**\n",
        "\n",
        "* Input: Image\n",
        "* Output: Sentence\n",
        "\n",
        "  > â€œA dog is playing in the parkâ€\n",
        "\n",
        "### Why RNN?\n",
        "\n",
        "* One input (image)\n",
        "* Generates a **sequence of words**\n",
        "\n",
        "---\n",
        "\n",
        "## 3ï¸âƒ£ Many-to-One RNN â­ (Most Common)\n",
        "\n",
        "### Diagram\n",
        "\n",
        "```\n",
        "Input1 â†’ Input2 â†’ Input3 â†’ Input4\n",
        "   â†“        â†“        â†“        â†“\n",
        "  h1 â†’ h2 â†’ h3 â†’ h4 â”€â”€â”€â–º Output\n",
        "```\n",
        "\n",
        "### Real-Time Examples\n",
        "\n",
        "* **Sentiment analysis**\n",
        "\n",
        "  * â€œThis movie is very goodâ€ â†’ Positive\n",
        "* **Spam detection**\n",
        "\n",
        "  * Email text â†’ Spam / Not Spam\n",
        "* **Emotion detection**\n",
        "\n",
        "### Why RNN?\n",
        "\n",
        "* Output depends on **entire sequence**\n",
        "* Order of words matters\n",
        "\n",
        "ğŸ“Œ **Most NLP classification problems use this**\n",
        "\n",
        "---\n",
        "\n",
        "## 4ï¸âƒ£ Many-to-Many RNN (Same Length)\n",
        "\n",
        "### Diagram\n",
        "\n",
        "```\n",
        "Input1 â†’ Input2 â†’ Input3\n",
        "   â†“        â†“        â†“\n",
        " Output1 â†’ Output2 â†’ Output3\n",
        "```\n",
        "\n",
        "### Real-Time Examples\n",
        "\n",
        "ğŸ—£ **Speech Recognition**\n",
        "\n",
        "* Audio frames â†’ Text characters\n",
        "\n",
        "ğŸ“Œ Input and output sequence lengths are the **same**.\n",
        "\n",
        "---\n",
        "\n",
        "## 5ï¸âƒ£ Many-to-Many RNN (Different Length) â­â­\n",
        "\n",
        "### Diagram (Encoderâ€“Decoder)\n",
        "\n",
        "```\n",
        "Input1 â†’ Input2 â†’ Input3 â†’ Input4\n",
        "   â†“        â†“        â†“        â†“\n",
        "  Encoder Hidden State\n",
        "            â†“\n",
        " Output1 â†’ Output2 â†’ Output3\n",
        "```\n",
        "\n",
        "### Real-Time Examples\n",
        "\n",
        "ğŸŒ **Machine Translation**\n",
        "\n",
        "* English sentence â†’ French sentence\n",
        "* â€œI love AIâ€ â†’ â€œJâ€™aime lâ€™IAâ€\n",
        "\n",
        "ğŸ§  **Chatbots**\n",
        "\n",
        "* User message â†’ Reply sentence\n",
        "\n",
        "ğŸ“Œ Uses **Encoderâ€“Decoder RNN**\n",
        "\n",
        "---\n",
        "\n",
        "## 6ï¸âƒ£ Bidirectional RNN (Advanced)\n",
        "\n",
        "### Diagram\n",
        "\n",
        "```\n",
        "Forward:   x1 â†’ x2 â†’ x3 â†’ x4\n",
        "Backward:  x1 â† x2 â† x3 â† x4\n",
        "```\n",
        "\n",
        "### Real-Time Example\n",
        "\n",
        "ğŸ“– **Text understanding**\n",
        "\n",
        "* â€œI went to the bank to deposit moneyâ€\n",
        "\n",
        "To know *bank* = financial bank, model needs:\n",
        "\n",
        "* Past words\n",
        "* Future words\n",
        "\n",
        "ğŸ“Œ Bidirectional RNN reads sequence **both ways**.\n",
        "\n",
        "---\n",
        "\n",
        "## 7ï¸âƒ£ Stacked (Deep) RNN\n",
        "\n",
        "### Diagram\n",
        "\n",
        "```\n",
        "Input\n",
        " â†“\n",
        "RNN Layer 1\n",
        " â†“\n",
        "RNN Layer 2\n",
        " â†“\n",
        "RNN Layer 3\n",
        " â†“\n",
        "Output\n",
        "```\n",
        "\n",
        "### Real-Time Example\n",
        "\n",
        "* Speech recognition\n",
        "* Language modeling\n",
        "\n",
        "ğŸ“Œ More layers â†’ more complex patterns\n",
        "\n",
        "---\n",
        "\n",
        "## 8ï¸âƒ£ RNN Variants (Used in Practice)\n",
        "\n",
        "| Type       | Why Used        | Real Example           |\n",
        "| ---------- | --------------- | ---------------------- |\n",
        "| Simple RNN | Learning basics | Toy examples           |\n",
        "| LSTM       | Long memory     | Translation, chatbots  |\n",
        "| GRU        | Faster, simpler | Time-series prediction |\n",
        "\n",
        "---\n",
        "\n",
        "## Summary Table (Very Exam-Friendly)\n",
        "\n",
        "| Type                | Input    | Output   | Example              |\n",
        "| ------------------- | -------- | -------- | -------------------- |\n",
        "| One-to-One          | Single   | Single   | Image classification |\n",
        "| One-to-Many         | Single   | Sequence | Image captioning     |\n",
        "| Many-to-One         | Sequence | Single   | Sentiment analysis   |\n",
        "| Many-to-Many (same) | Sequence | Sequence | Speech recognition   |\n",
        "| Many-to-Many (diff) | Sequence | Sequence | Translation          |\n",
        "| Bidirectional       | Sequence | Sequence | NLP understanding    |\n",
        "\n",
        "---\n",
        "\n",
        "## Simple Way to Remember â­\n",
        "\n",
        "> **ANN** sees one thing at a time.\n",
        "> **RNN** remembers the story.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QSaTUo-Mp9yT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1ï¸âƒ£ **Many-to-One RNN (Sentiment Analysis)**\n",
        "\n",
        "Movie review â†’ Positive / Negative\n",
        "\n",
        "Email â†’ Spam / Not spam"
      ],
      "metadata": {
        "id": "CpCiIul6qVp5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "xGHO_dAMp6AD",
        "outputId": "de76712c-7c50-4100-a1a7-8c2e3f708390"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=100, output_dim=8, input_length=5))\n",
        "model.add(SimpleRNN(16))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# âœ… Example 1: **Many-to-One RNN**\n",
        "\n",
        "### (Sequence â†’ Single Output)\n",
        "\n",
        "ğŸ“Œ *Most common use: Sentiment Analysis*\n",
        "\n",
        "### Code\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keraslayers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=100, output_dim=8, input_length=5))\n",
        "model.add(SimpleRNN(16))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### What is happening here?\n",
        "\n",
        "#### Input (sentence)\n",
        "\n",
        "```\n",
        "\"I love this movie\"\n",
        "```\n",
        "\n",
        "After tokenization:\n",
        "\n",
        "```\n",
        "[4, 12, 7, 9, 0]   â† sequence length = 5\n",
        "```\n",
        "\n",
        "#### Flow\n",
        "\n",
        "```\n",
        "Numbers â†’ Embedding â†’ RNN â†’ Dense â†’ Output\n",
        "```\n",
        "\n",
        "* **Embedding** gives meaning to each word\n",
        "* **RNN** reads words one by one and remembers context\n",
        "* **Dense(1)** gives final prediction\n",
        "\n",
        "#### Output\n",
        "\n",
        "```\n",
        "0.85 â†’ Positive\n",
        "0.20 â†’ Negative\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# âœ… Example 2: **Many-to-Many RNN (Same Length)**\n",
        "\n",
        "### (Sequence â†’ Sequence)\n",
        "\n",
        "ğŸ“Œ *Used in tagging or next-word prediction*\n",
        "\n",
        "### Code\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(50, 8, input_length=5))\n",
        "model.add(SimpleRNN(16, return_sequences=True))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation\n",
        "\n",
        "* Each input word produces an output\n",
        "* `return_sequences=True` means:\n",
        "  ğŸ‘‰ â€œGive output at every time stepâ€\n",
        "\n",
        "Example:\n",
        "\n",
        "```\n",
        "Input:  [2, 5, 8, 6, 3]\n",
        "Output: [w1, w2, w3, w4, w5]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# âœ… Example 3: **Embedding + RNN (Very Common Pattern)**\n",
        "\n",
        "### Code\n",
        "\n",
        "```python\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(200, 16, input_length=6))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Real-world meaning\n",
        "\n",
        "Sentence:\n",
        "\n",
        "```\n",
        "\"I am learning deep learning\"\n",
        "```\n",
        "\n",
        "Classes:\n",
        "\n",
        "```\n",
        "0 â†’ Tech\n",
        "1 â†’ Sports\n",
        "2 â†’ Politics\n",
        "```\n",
        "\n",
        "Output:\n",
        "\n",
        "```\n",
        "[0.90, 0.05, 0.05] â†’ Tech\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ” Example 4: **RNN vs LSTM (Industry Standard)**\n",
        "\n",
        "### Code (LSTM â€“ better memory)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(100, 16, input_length=5))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "ğŸ‘‰ Same idea as RNN, but:\n",
        "\n",
        "* Remembers longer sentences\n",
        "* Used more in real applications\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ§© Simple Input â†’ Output Flow (Easy to Remember)\n",
        "\n",
        "```\n",
        "Text\n",
        " â†“\n",
        "Tokenized numbers\n",
        " â†“\n",
        "Embedding (meaning)\n",
        " â†“\n",
        "RNN / LSTM (memory)\n",
        " â†“\n",
        "Dense layer (decision)\n",
        " â†“\n",
        "Output\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ğŸ”š Summary (Plain English)\n",
        "\n",
        "* **Embedding** â†’ converts words into meaningful vectors\n",
        "* **RNN** â†’ reads data step by step and remembers context\n",
        "* **Dense layer** â†’ makes final prediction\n",
        "* **Many-to-One** â†’ sentence â†’ label\n",
        "* **Many-to-Many** â†’ sequence â†’ sequence\n",
        "* **LSTM** â†’ advanced RNN with better memory\n",
        "\n"
      ],
      "metadata": {
        "id": "N5SvShY-rKix"
      }
    }
  ]
}