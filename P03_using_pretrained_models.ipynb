{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What is a Pretrained Model?\n",
        "\n",
        "A **pretrained model** is a deep learning model that has already been **trained on a very large dataset** and has learned **general features** that can be reused for new tasks.\n",
        "\n",
        "Instead of training a model **from scratch**, we reuse its learned knowledge.\n",
        "\n",
        "ğŸ“Œ Example pretrained CNNs:\n",
        "\n",
        "* VGG16 / VGG19\n",
        "* ResNet\n",
        "* Inception\n",
        "* MobileNet\n",
        "* EfficientNet\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Why We Use Pretrained Models\n",
        "\n",
        "Training deep neural networks from scratch requires:\n",
        "\n",
        "* Huge datasets\n",
        "* High computational power\n",
        "* Long training time\n",
        "\n",
        "### Pretrained models solve this by:\n",
        "\n",
        "### âœ… 1. Faster Training\n",
        "\n",
        "* Model already knows basic features (edges, shapes, textures)\n",
        "* Only fine-tuning is required\n",
        "\n",
        "### âœ… 2. Higher Accuracy\n",
        "\n",
        "* Learned from millions of images\n",
        "* Better generalization on small datasets\n",
        "\n",
        "### âœ… 3. Less Data Required\n",
        "\n",
        "* Works well even with limited datasets\n",
        "\n",
        "### âœ… 4. Reduced Overfitting\n",
        "\n",
        "* Learned robust and transferable features\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Where Pretrained Models Are Used\n",
        "\n",
        "| Domain             | Usage                                         |\n",
        "| ------------------ | --------------------------------------------- |\n",
        "| Computer Vision    | Image classification, detection, segmentation |\n",
        "| Medical Imaging    | Disease detection (X-ray, MRI)                |\n",
        "| Autonomous Driving | Object & traffic sign recognition             |\n",
        "| Face Recognition   | Identity & expression detection               |\n",
        "| Remote Sensing     | Satellite image analysis                      |\n",
        "\n",
        "---\n",
        "\n",
        "## 4. How Pretrained Models Are Used (Transfer Learning)\n",
        "\n",
        "### Method 1: Feature Extraction\n",
        "\n",
        "* Freeze all pretrained layers\n",
        "* Train only new classifier layers\n",
        "\n",
        "ğŸ“Œ Used when dataset is small\n",
        "\n",
        "---\n",
        "\n",
        "### Method 2: Fine-Tuning\n",
        "\n",
        "* Freeze early layers\n",
        "* Unfreeze top layers\n",
        "* Train with small learning rate\n",
        "\n",
        "ğŸ“Œ Used when dataset is medium/large\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Why Pretrained Models Work (Intuition)\n",
        "\n",
        "CNN layers learn features hierarchically:\n",
        "\n",
        "| Layer Type    | Learned Features |\n",
        "| ------------- | ---------------- |\n",
        "| Early layers  | Edges, corners   |\n",
        "| Middle layers | Shapes, textures |\n",
        "| Deep layers   | Objects, parts   |\n",
        "\n",
        "These features are **generic** and reusable across tasks.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Benefits Summary (One Look)\n",
        "\n",
        "| Benefit     | Explanation           |\n",
        "| ----------- | --------------------- |\n",
        "| Efficiency  | Saves time & compute  |\n",
        "| Accuracy    | Better performance    |\n",
        "| Scalability | Works with small data |\n",
        "| Stability   | Less overfitting      |\n",
        "\n",
        "---\n",
        "\n",
        "# **Part 2: ImageNet Dataset**\n",
        "\n",
        "---\n",
        "\n",
        "## 7. What is ImageNet?\n",
        "\n",
        "**ImageNet** is a **large-scale visual database** designed for training and benchmarking image recognition models.\n",
        "\n",
        "It is one of the **most influential datasets in deep learning history**.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. What ImageNet Contains\n",
        "\n",
        "| Feature         | Description             |\n",
        "| --------------- | ----------------------- |\n",
        "| Total images    | ~14 million             |\n",
        "| Training images | ~1.2 million            |\n",
        "| Classes         | 1,000 object categories |\n",
        "| Image type      | Real-world RGB images   |\n",
        "| Labels          | Human-annotated         |\n",
        "\n",
        "Examples of classes:\n",
        "\n",
        "* Animals (dog, cat, bird)\n",
        "* Objects (car, chair, bottle)\n",
        "* Nature (mountain, river)\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Why ImageNet Is Important\n",
        "\n",
        "### âœ… 1. Large & Diverse\n",
        "\n",
        "* Covers wide range of real-world objects\n",
        "* Reduces dataset bias\n",
        "\n",
        "### âœ… 2. Benchmark Standard\n",
        "\n",
        "* Used in ImageNet Large Scale Visual Recognition Challenge (ILSVRC)\n",
        "* Led to breakthroughs like **AlexNet, ResNet**\n",
        "\n",
        "### âœ… 3. Enables Transfer Learning\n",
        "\n",
        "* Models trained on ImageNet learn **universal visual features**\n",
        "\n",
        "---\n",
        "\n",
        "## 10. How ImageNet Is Used\n",
        "\n",
        "### Training Phase\n",
        "\n",
        "* Models trained on millions of images\n",
        "* Learn robust representations\n",
        "\n",
        "### Transfer Learning Phase\n",
        "\n",
        "* ImageNet-trained weights reused\n",
        "* Fine-tuned for specific tasks\n",
        "\n",
        "---\n",
        "\n",
        "## 11. Why ImageNet Features Transfer Well\n",
        "\n",
        "Because:\n",
        "\n",
        "* Images are **natural and diverse**\n",
        "* Visual features are **generic**\n",
        "* Covers most real-world patterns\n",
        "\n",
        "Thus:\n",
        "\n",
        "> A model trained on ImageNet can recognize edges, textures, and shapes useful for almost any vision task.\n",
        "\n",
        "---\n",
        "\n",
        "## 12. ImageNet vs Training From Scratch\n",
        "\n",
        "| Aspect        | ImageNet Pretraining | From Scratch |\n",
        "| ------------- | -------------------- | ------------ |\n",
        "| Data needed   | Small                | Very large   |\n",
        "| Training time | Short                | Long         |\n",
        "| Accuracy      | High                 | Often lower  |\n",
        "| Overfitting   | Less                 | More         |\n",
        "\n",
        "---\n",
        "\n",
        "## 13. Relationship Between Pretrained Models & ImageNet\n",
        "\n",
        "* Most pretrained CNNs are trained on **ImageNet**\n",
        "* ImageNet acts as **knowledge base**\n",
        "* Pretrained models act as **feature extractors**\n",
        "\n",
        "ğŸ“Œ Without ImageNet, modern transfer learning would not exist.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 15. Final Summary\n",
        "\n",
        "* Pretrained models save time, data, and computation\n",
        "* ImageNet provides rich visual knowledge\n",
        "* Together they form the backbone of modern computer vision\n",
        "* Essential for high accuracy with limited data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e58spINMQNRo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1QHfQuRxo2NAQJKsJodsObcLgf48Vt2m5?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YegWxg7tcuEs"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDQzKK9fdGSz",
        "outputId": "71c3d465-f8fa-4eff-e757-54920f1b36a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/download (1).jfif'\n",
        "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
        "x = keras.utils.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "metadata": {
        "id": "7hCDkV6adIoq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMSY2W0sddtT",
        "outputId": "76da357c-817a-4c87-922a-682597c81595"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Predicted: [('n02127052', 'lynx', np.float32(0.8978003)), ('n02123045', 'tabby', np.float32(0.01657708)), ('n02124075', 'Egyptian_cat', np.float32(0.015172523))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/download.jfif'\n",
        "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
        "x = keras.utils.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "metadata": {
        "id": "mRMtPP6Od1nY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXiBXHcTd6A_",
        "outputId": "d46678e7-b4ab-4a3d-a60b-721890e3ec15"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Predicted: [('n02089973', 'English_foxhound', np.float32(0.5259784)), ('n02089867', 'Walker_hound', np.float32(0.272138)), ('n02088364', 'beagle', np.float32(0.14267507))]\n"
          ]
        }
      ]
    }
  ]
}